from __future__ import print_function

#from datapre2 import *

#from model import *

#import warnings



# -*- coding:utf-8 -*-

# Author : Ray

# Data : 2019/7/23 4:53 PM



from keras.models import *

from keras.layers import *

from keras.optimizers import *

from keras.callbacks import ModelCheckpoint, LearningRateScheduler



from keras import backend as keras

import tensorflow as tf





from keras.preprocessing.image import ImageDataGenerator



import numpy as np 



import os



import glob



import skimage.io as io



import skimage.transform as trans





'''Sky = [128,128,128]



Building = [128,0,0]



Pole = [192,192,128]



Road = [128,64,128]



Pavement = [60,40,222]



Tree = [128,128,0]



SignSymbol = [192,128,128]



Fence = [64,64,128]



Car = [64,0,128]



Pedestrian = [64,64,0]



Bicyclist = [0,128,192]



Unlabelled = [0,0,0]



 



COLOR_DICT = np.array([Sky, Building, Pole, Road, Pavement,



                          Tree, SignSymbol, Fence, Car, Pedestrian, Bicyclist, Unlabelled])'''





circle = [0,64,0]



cell = [255,0,0]



background = [0,0,0]







COLOR_DICT = np.array([ circle, cell, background])   #调整显色模式












def trainGenerator(batch_size,aug_dict,train_path,image_folder,label_folder,image_color_mode='rgb',

                   label_color_mode='rgb',image_save_prefix='image',label_save_prefix='label',

                   flag_multi_class=True,num_class=3,save_to_dir=None,target_size=(256,256),seed=1):

    image_datagen = ImageDataGenerator(**aug_dict)

    label_datagen = ImageDataGenerator(**aug_dict)

    image_generator = image_datagen.flow_from_directory(

        train_path,

        classes=[image_folder],

        class_mode=None,

        color_mode=image_color_mode,

        target_size = target_size,

        batch_size = batch_size,

        save_to_dir = save_to_dir,

        save_prefix = image_save_prefix,

        seed = seed

    )

    label_generator = label_datagen.flow_from_directory(

        train_path,

        classes = [label_folder],

        class_mode = None,

        color_mode = label_color_mode,

        target_size = target_size,

        batch_size = batch_size,

        save_to_dir = save_to_dir,

        save_prefix = label_save_prefix,

        seed = seed

    )

    train_generator = zip(image_generator,label_generator)

    for img,label in train_generator:

        img,label = adjustData(img,label,flag_multi_class,num_class)

        # print('------2-------',img.shape,label.shape)#(2, 512, 512, 3) (2, 512, 0, 3, 13)

        yield img,label

print(2)

def valGenerator(batch_size,aug_dict,val_path,image_folder,label_folder,image_color_mode='rgb',

                   label_color_mode='rgb',image_save_prefix='image',label_save_prefix='label',

                   flag_multi_class=True,num_class=3,save_to_dir=None,target_size=(256,256),seed=1):

    print(4)

    image_datagen = ImageDataGenerator(**aug_dict)

    label_datagen = ImageDataGenerator(**aug_dict)

    val_image_generator = image_datagen.flow_from_directory(

        val_path,

        classes=[image_folder],

        class_mode = None,

        color_mode = image_color_mode,

        target_size = target_size,

        batch_size = batch_size,

        save_to_dir = save_to_dir,

        save_prefix  = image_save_prefix,

        seed = seed

        )

    val_label_generator = label_datagen.flow_from_directory(

        val_path,

        classes = [label_folder],

        class_mode = None,

        color_mode = label_color_mode,

        target_size = target_size,

        batch_size = batch_size,

        save_to_dir = save_to_dir,

        save_prefix  = label_save_prefix,

        seed = seed

        )

    val_generator = zip(val_image_generator, val_label_generator)

    for (img,label) in val_generator:

        img ,label = adjustData(img, label, flag_multi_class, num_class)

        yield img,label

        

        

print(6)

'''def adjustData(img,label,flag_multi_class,num_class):

    if (flag_multi_class):

        img = img/255.

        label = label[:,:,:,0] if (len(label.shape)==4) else label[:,:,0]

        # print('-----1-----', img.shape, label.shape)

        new_label = np.zeros(label.shape+(num_class,))

        # print('new_label.shape',new_label.shape)

        for i in range(num_class):

            new_label[label==i,i] = 1

        label = new_label

    elif (np.max(img)>1):

        img = img/255.

        label = label/255.

        label[label>0.5] = 1

        label[label<=0.5] = 0

    return (img,label)'''





def adjustData(img,label,flag_multi_class,num_class):



    if(flag_multi_class):



        img = img / 255.0
       



        label = label[:,:,:,0] if(len(label.shape) == 4) else label[:,:,0]



        #label[(label!=0.)&(label!=255.0)&(label!=128.)] = 0.



        new_label = np.zeros(label.shape + (num_class,))
        new_label[label == 75,   0] = 1



        new_label[label == 38,   1] = 1



        new_label[label == 0,   2] = 1



        label = new_label


    elif (np.max(img)>1):



        img = img/255.



        label = label/255.



        label[label>0.5] = 1



        label[label<=0.5] = 0



    return (img,label)
        

       







print(8)

def testGenerator(test_path,target_size=(256,256),flag_multi_class=True,as_gray=False):

    filenames = os.listdir(test_path)

    for filename in filenames:

        img = io.imread(os.path.join(test_path,filename),as_gray=as_gray)

        #img = img/255.0            #转换图片？

        img = trans.resize(img,target_size,mode = 'constant')

        img = np.reshape(img,img.shape+(1,)) if (not flag_multi_class) else img

        img = np.reshape(img,(1,)+img.shape)

        yield img



        

print(10)

def saveResult(save_path,npyfile,flag_multi_class=True):

    for i,item in enumerate(npyfile):

        if flag_multi_class:

            img = item

            img_out = np.zeros(img[:, :, 0].shape + (3,))

            for row in range(img.shape[0]):

                for col in range(img.shape[1]):

                    index_of_class = np.argmax(img[row, col])

                    img_out[row, col] = COLOR_DICT[index_of_class]

            img = img_out.astype(np.uint8)

            io.imsave(os.path.join(save_path, '%s_predict.png' % i), img)

        else:

            img = item[:, :, 0]

            img[img > 0.5] = 1

            img[img <= 0.5] = 0

            img = img * 255.0

            io.imsave(os.path.join(save_path, '%s_predict.png' % i), img)



print(12)            





IMAGE_SIZE = 256

print(14)

def unet(pretrained_weights = None, input_size = (IMAGE_SIZE,IMAGE_SIZE,3),num_class=3):         #源程序中是 num_class=2

    inputs = Input(input_size)

    conv1 = Conv2D(64,3,activation=None,padding='same',kernel_initializer='he_normal')(inputs)

    conv1 = LeakyReLU(alpha=0.3)(conv1)

    conv1 = Conv2D(64,3,activation=None,padding='same',kernel_initializer='he_normal')(conv1)

    conv1 = LeakyReLU(alpha=0.3)(conv1)

    pool1 = MaxPool2D(pool_size=(2,2))(conv1)



    conv2 = Conv2D(128,3,activation=None,padding='same',kernel_initializer='he_normal')(pool1)

    conv2 = LeakyReLU(alpha=0.3)(conv2)

    conv2 = Conv2D(128,3,activation=None,padding='same',kernel_initializer='he_normal')(conv2)

    conv2 = LeakyReLU(alpha=0.3)(conv2)

    pool2 = MaxPool2D(pool_size=(2,2))(conv2)



    conv3 = Conv2D(256,3,activation=None,padding='same',kernel_initializer='he_normal')(pool2)

    conv3 = LeakyReLU(alpha=0.3)(conv3)

    conv3 = Conv2D(256,3,activation=None,padding='same',kernel_initializer='he_normal')(conv3)

    conv3 = LeakyReLU(alpha=0.3)(conv3)

    pool3 = MaxPool2D(pool_size=(2,2))(conv3)



    conv4 = Conv2D(512,3,activation=None,padding='same',kernel_initializer='he_normal')(pool3)

    conv4 = LeakyReLU(alpha=0.3)(conv4)

    conv4 = Conv2D(512,3,activation=None,padding='same',kernel_initializer='he_normal')(conv4)

    conv4 = LeakyReLU(alpha=0.3)(conv4)

    drop4 = Dropout(0.5)(conv4)

    pool4 = MaxPool2D(pool_size=(2,2))(drop4)



    conv5 = Conv2D(1024,3,activation=None,padding='same',kernel_initializer='he_normal')(pool4)

    conv5 = LeakyReLU(alpha=0.3)(conv5)

    conv5 = Conv2D(1024,3,activation=None,padding='same',kernel_initializer='he_normal')(conv5)

    conv5 = LeakyReLU(alpha=0.3)(conv5)

    drop5 = Dropout(0.5)(conv5)



    up6 = Conv2D(512,2,activation=None,padding='same',kernel_initializer='he_normal')(UpSampling2D(size=(2,2))(drop5))

    up6 = LeakyReLU(alpha=0.3)(up6)

    merge6 = concatenate([drop4,up6],axis=3)

    conv6 = Conv2D(512,3,activation=None,padding='same',kernel_initializer='he_normal')(merge6)

    conv6 = LeakyReLU(alpha=0.3)(conv6)

    conv6 = Conv2D(512,3,activation=None,padding='same',kernel_initializer='he_normal')(conv6)

    conv6 = LeakyReLU(alpha=0.3)(conv6)



    up7 = Conv2D(256,3,activation=None,padding='same',kernel_initializer='he_normal')(UpSampling2D(size=(2,2))(conv6))

    up7 = LeakyReLU(alpha=0.3)(up7)

    merge7 = concatenate([conv3,up7],axis=3)

    conv7 = Conv2D(256,3,activation=None,padding='same',kernel_initializer='he_normal')(merge7)

    conv7 = LeakyReLU(alpha=0.3)(conv7)

    conv7 = Conv2D(256,3,activation=None,padding='same',kernel_initializer='he_normal')(conv7)

    conv7 = LeakyReLU(alpha=0.3)(conv7)





    up8 = Conv2D(128,3,activation=None,padding='same',kernel_initializer='he_normal')(UpSampling2D(size=(2,2))(conv7))

    up8 = LeakyReLU(alpha=0.3)(up8)

    merge8 = concatenate([conv2,up8],axis=3)

    conv8 = Conv2D(128,3,activation=None,padding='same',kernel_initializer='he_normal')(merge8)

    conv8 = LeakyReLU(alpha=0.3)(conv8)

    conv8 = Conv2D(128,3,activation=None,padding='same',kernel_initializer='he_normal')(conv8)

    conv8 = LeakyReLU(alpha=0.3)(conv8)



    up9 = Conv2D(64,3,activation=None,padding='same',kernel_initializer='he_normal')(UpSampling2D(size=(2,2))(conv8))

    up9 = LeakyReLU(alpha=0.3)(up9)

    merge9 = concatenate([conv1,up9],axis=3)

    conv9 = Conv2D(64,3,activation=None,padding='same',kernel_initializer='he_normal')(merge9)

    conv9 = LeakyReLU(alpha=0.3)(conv9)

    conv9 = Conv2D(64,3,activation=None,padding='same',kernel_initializer='he_normal')(conv9)

    conv9 = LeakyReLU(alpha=0.3)(conv9)

    print(14)

    if num_class == 2:#判断是否多分类问题，二分类激活函数使用sigmoid，而多分割采用softmax。相应的损失函数的选择也各有不同。

        conv10 = Conv2D(1,1,activation='sigmoid')(conv9)

        loss_function = 'binary_crossentropy'

    else:

        conv10 = Conv2D(num_class,1,activation='softmax')(conv9)

        loss_function = 'categorical_crossentropy'



    # conv10 = Conv2D(3,1,activation='softamx')(conv9)

    print(16)

    model = Model(input= inputs,output=conv10)



    model.compile(optimizer=Adam(lr = 1e-4),loss=loss_function,metrics=['accuracy'])

    model.summary()

    print(18)



    if pretrained_weights:

        model.load_weights(pretrained_weights)



    return model











        

        

# -*- coding:utf-8 -*-

# Author : Ray

# Data : 2019/7/25 2:15 PM









print(20)

#warnings.filterwarnings('ignore')	#忽略警告信息

# os.environ['CUDA_VISIBLE_DEVICES'] = '0'	#设置GPU

#测试集233张，训练集367张，校准集101张，总共233+367+101=701张，图像大小为360*480，语义类别为13类



aug_args = dict( #设置ImageDataGenerator参数

    rotation_range = 0.2,

    width_shift_range = 0.05,

    height_shift_range = 0.05,

    shear_range = 0.05,

    zoom_range = 0.05,

    horizontal_flip = True,

    vertical_flip = True,

    fill_mode = 'nearest'

)

print(22)

train_gene = trainGenerator(batch_size=2,aug_dict=aug_args,train_path='C:\\cell3\\',

                        image_folder='train3',label_folder='trainannot3',

                        image_color_mode='rgb',label_color_mode='rgb',

                        image_save_prefix='image',label_save_prefix='label',

                        flag_multi_class=True,save_to_dir=None

                        )

val_gene = valGenerator(batch_size=2,aug_dict=aug_args,val_path='C:\\cell3\\validation3\\',

                       image_folder='val3',label_folder='valannot3',

                       image_color_mode='rgb',label_color_mode='rgb',

                       image_save_prefix='image',label_save_prefix='label',

                       flag_multi_class=True,save_to_dir=None

                       )

print('val_path')

#tensorboard = TensorBoard(log_dir='./log')

model = unet(num_class=3)

model_checkpoint = ModelCheckpoint('camvid.hdf5',monitor='val_loss',verbose=1,save_best_only=True)

print(24)

history = model.fit_generator(train_gene,

                              steps_per_epoch=100,

                              epochs=10,

                              verbose=1,

                              callbacks=[model_checkpoint],

                              validation_data=val_gene,

                              validation_steps=100   #validation/batchsize

                              )

# model.load_weights('camvid.hdf5')

test_gene = testGenerator(test_path='C:\\cell3\\test3')

results = model.predict_generator(test_gene,10,verbose=1)

saveResult('C:\\cell3\\testpred3\\',results)
